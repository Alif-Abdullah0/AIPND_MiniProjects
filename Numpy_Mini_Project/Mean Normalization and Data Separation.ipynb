{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4915 1504 1226 ..., 2448 3974 4716]\n",
      " [2481 2141 2944 ...,  779  448 1465]\n",
      " [2380 2646 3635 ..., 4414  170 4952]\n",
      " ..., \n",
      " [2620 4439  574 ..., 2267 1682 3192]\n",
      " [4170 3252 1586 ..., 4648 2710 3398]\n",
      " [2489 2960 2583 ..., 4137 4579 4360]]\n",
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0,5001,size=(1000,20))\n",
    "\n",
    "# print the shape of X\n",
    "print(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2502.33   2492.366  2530.654  2514.398  2472.911  2518.507  2575.853\n",
      "  2495.425  2443.828  2483.813  2472.913  2529.937  2596.869  2394.429\n",
      "  2504.687  2463.162  2516.863  2498.975  2493.712  2474.165] [ 1473.71098561  1463.31645793  1417.70371738  1448.48140533  1489.15771733\n",
      "  1425.51605952  1441.57013891  1445.8612535   1438.49391393  1438.1654446\n",
      "  1423.55849315  1441.16761587  1439.7371329   1390.43443749  1408.20041082\n",
      "  1468.19307441  1438.24147911  1447.27326044  1436.08467057  1431.36219797]\n"
     ]
    }
   ],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = np.mean(X, axis=0)\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = np.std(X, axis=0)\n",
    "print(ave_cols, std_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols.shape)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X-ave_cols)/std_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.13162820728e-18\n",
      "-1.56984657834\n",
      "1.57582744683\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(np.mean(X_norm))\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(np.mean(np.min(X_norm, axis=1)))\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(np.mean(np.max(X_norm, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 0, 2, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[623 754 115  17 134 348  79  37  31 718 443 322 602 403  53 885 350 280\n",
      " 515 914 812  64 958 877 408 619 462 820 492 494 924 845  10 665 158   4\n",
      " 226 228 823 640 670 526 575 345 156 880 934 316 457 356 706 534 154 868\n",
      " 284 487 988 601 647 883 184 180 465 618 762  67 748 516 903 625  72 986\n",
      " 712 260 904 249 755 702 816 306 925 663  97 181 198 668 622 414 634 689\n",
      " 204 704 827  19 957 997 496 477 691 522 841 927 278   6 248 344  48   8\n",
      " 331  34 206 520 337 342 858 654 855 785 295 757 639 155  36  65 556 804\n",
      " 167 774 666 401 797 255 191 759 693 294  58 847 286 469 418 731 937 696\n",
      " 882 859 392 976 865 452 326 621 945 233 850 400 483 570  32 728 786 690\n",
      " 864 323 735 662 783 935 840 542 547 519 119 289 320 441 787 973 843 614\n",
      " 521 814 455 984  40 493 900  15 312 775  94  27 135 948 829 788 523 643\n",
      " 235  63 215 671 821 268 738 415 389 830 272  20 197 103 178 908 800 657\n",
      " 174 202 677 231 377 959 834 846 806 980  39 692 540 798 475 624   5 114\n",
      " 338 913 529 486  11 187 444 343 713 767 559 381 709 969 714 225 682 964\n",
      " 536 508 386 796 792 505 894 849 461  68 708 917 897 491 985 949 176 336\n",
      " 991 190 232 564 501 616   7 590 138 175 972 844 642   1 789 513 687 296\n",
      " 967 977 192 143 778 950 243 417 262 524 930 240  90 822 604 631 162   0\n",
      " 362 485  80  54 683 239 565 109  91 881 376 549 697 404 655 902 385 548\n",
      " 685 297 569  84 329 838 879 566 983 244  23 721 495 752 166 848 288 891\n",
      " 478 739 869 110 125 734 214 307 189 620 592 839 965 888 649 722 165 831\n",
      " 886 173 510  45 468 906 887 292 746 269 106 211 733 325 870 327 742 586\n",
      " 132 819 410 701  74 283 511 599 464 896 321 871 145 576 910 828 437 366\n",
      " 747 328 955 266 185 528 824 163 750 577 595 794 817 790  25 968 652 727\n",
      " 416 122 588 963  52 357 630 942 379 195 432 236 227 672 281 245 818 873\n",
      " 480 164 318 545 552 300 139 250 912 698 805 129 533 210 121  75 355  93\n",
      " 961  92 279 105 256 995 664 943 793 369 298  96 641 918 635 605  13 667\n",
      " 411  50 218 644 981 773  95 539  47  35  71 872 347 607 188 561 484 929\n",
      " 598 353 835 409 313 393 756 597 940 220 481 971 893 583 131 223 725 758\n",
      " 199 730 574 205  41 952 285  62 422 209 391 148  55 780 993 150 720 436\n",
      " 530 627 241 375 921 463 546 500 399 264 434 365 863 975 781 587 979 310\n",
      " 705 926  22 472 380 216 152 200 387 776 253 123  29  26 459 351 962 557\n",
      " 429 349 772 699 333 127 263 324 503  33 502 100 593 147 990 512 898 193\n",
      " 802 686 603 953 270 334 479 518 724 424  77 928 573 656 339  42 212 442\n",
      " 931 651 749  61 207 169 538 645 554 299  18 933 111 304  43 543 726 920\n",
      " 196 611 177 637  21 837 398  28 419 741 889 596 694 275 332 439 160 674\n",
      " 311 646 346 947 911 234 600 406 172 810 274 157 358  38  70 919  59 615\n",
      " 771 229 999  88 458 140 359 394 736 779 141 874 782 116 833 594   2  69\n",
      " 221 716 673 257 609 541  56 678 740 454 382  30 473 606 161 719 430 259\n",
      " 803 309 146  82 396 222 989 151 899 446 170  51 126 996 302 238 905 447\n",
      " 808  16 710 317 525 922  49 405 892 535 763 413 474 584 133 684 901 390\n",
      " 168 815 183 448 305 291 703 571 230 707 340 653 954 267 246 364 578 617\n",
      " 966 352 449 970 737 744 213  98 987 315 854  78 768 368 941 120 179 550\n",
      " 118 626 978  12 878  66 946 277 374 799 998  86 795 384  14 438 801 579\n",
      " 553 560 159 791 101 504 585 760 580 890 688 224 104 765 659 453 729 866\n",
      " 412 711 497 130 681 378 679 144 638 258 137 371 563 723 784 567 956 107\n",
      "  89 470   3   9 271 506 860 319 527 753 171 293 426 544 203 182 807 766\n",
      " 811 498 282 923 813 994 857 208 290 628 514 853 388 825 425 354 402 276\n",
      " 745  83  99 974 907 562 471 451 551 361 261 661 695 466 648 102 650 842\n",
      " 420 751 852 884 770 435 440 531 680 507  44 960 112 582 445 108 861 117\n",
      " 743 251 636 301 769  87 675 467 951 836 936 476 186 314 247 895 700  76\n",
      " 397 499 632 509 489 851 428 427 875 532 992 764 252 633 395 113 488 124\n",
      " 330 273 450 732 676  73 128 360 482 909 572 555 287 629  46 372 537 219\n",
      " 242 367 658 876 265  85 407  81 373 303 915 932 982 608 568 777 217 613\n",
      " 341 490 335 237 809 591 136 916 308 201 254 431 832 558 939 612 460 826\n",
      " 423  24 456 433 142 867 149 862 717  57 669 194 581 715 856 610 383  60\n",
      " 421 761 938 517 363 944 589 370 153 660]\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(X_norm.shape[0])\n",
    "print(row_indices)\n",
    "print(row_indices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = X_norm[row_indices[:600]]\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X_norm[row_indices[600:800]]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = X_norm[row_indices[800:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 20)\n",
      "(200, 20)\n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(X_train.shape)\n",
    "# Print the shape of X_crossVal\n",
    "print(X_crossVal.shape)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
